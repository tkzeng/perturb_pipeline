# =============================================================================
# DOWNSTREAM ANALYSIS PIPELINE
# =============================================================================
# This file contains rules for downstream analysis after initial processing
# including sublibrary combination and perturbation preprocessing
#
# To run: snakemake -s downstream.smk all_preprocessed --configfile config.yaml

import os
import sys
from scripts.pipeline_utils import get_guide_gex_pairings
from scripts.snakemake_helpers import (
    # Path helper functions
    get_scratch_path, get_results_path, get_logs_path,
    get_reference_path, get_raw_data_path, print_path_configuration,
    # Sample management functions
    load_sample_info, get_sample_ids, get_samples_by_type,
    extract_pool, extract_sample, get_sample_pool,
    # File finding functions
    find_fastq_file, print_sample_summary,
    # Output generation functions
    get_all_outputs
)

# Define base paths using helper functions
SCRATCH = get_scratch_path(config=config)
RESULTS = get_results_path(config=config)
LOGS = get_logs_path(config=config)
REFERENCES = get_reference_path(config=config)

# Load sample information and IDs
IDS = get_sample_ids(config)
GEX_IDS = get_samples_by_type('gex', config)
GUIDE_IDS = get_samples_by_type('guide', config)
# Get guide-GEX pairings from the centralized function
guide_to_gex, gex_to_guide = get_guide_gex_pairings(config['sample_info_file'])

# Wrapper function for load_sample_info  
def load_sample_info_wrapper():
    return load_sample_info(config)

rule all:
    """Target rule for downstream analysis pipeline"""
    input:
        # All preprocessed files based on configuration
        [f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{source}_{processing}.h5ad"
         for source, processing in config['combinations']]


# =============================================================================
# SUBLIBRARY COMBINATION
# =============================================================================
rule combine_sublibraries:
    """Combine cell-called sublibraries into a single analysis-ready file
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The combine_sublibraries.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        # Annotated h5ad files (have annotations but need cell calling applied)
        h5ad_files=lambda wildcards: [
            f"{SCRATCH}/{row['sample_id']}/kb_all_{wildcards.source}_{wildcards.processing}/counts_filtered/adata.h5ad"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Cell barcode files for the chosen method
        barcode_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/cell_calling/{row['sample_id']}_{config['combined_sublibraries']['cell_calling_method']}_cell_barcodes.txt"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Per-sample QC cell list files (generated by QC metrics rules)
        filter_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/qc_cell_lists.tsv"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        script="scripts/combine_sublibraries.py"
    output:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad"
    params:
        cell_calling_method=config['combined_sublibraries']['cell_calling_method'],
        qc_method=config['combined_sublibraries']['qc_method']
    log:
        f"{LOGS}/combine_sublibraries_{{source}}_{{processing}}.log"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        python {input.script} \
            --h5ad-files {input.h5ad_files} \
            --barcode-files {input.barcode_files} \
            --filter-files {input.filter_files} \
            --cell-calling-method {params.cell_calling_method} \
            --output {output.combined} \
            --qc-method {params.qc_method} \
            &> {log}
        """


# =============================================================================
# PERTURBATION PREPROCESSING AND ANALYSIS  
# =============================================================================
rule standard_analyses:
    """Standard analyses including normalization, HVG selection, clustering, UMAP, 
    cell cycle scoring, differential expression, and gene scoring.
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The standard_analyses.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad",
        script="scripts/standard_analyses.py"
    output:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad"
    params:
        target_genes=" ".join(config["standard_analyses"]["target_genes"]),
        use_gpu=config["standard_analyses"]["use_gpu"],
        target_clusters=config["standard_analyses"]["target_clusters"],
        guide_cutoff=config["standard_analyses"]["guide_assignment_cutoff"],
        stratification_column=config["standard_analyses"]["de_analysis_subsets"]["column"],
        stratification_values=" ".join(config["standard_analyses"]["de_analysis_subsets"]["values"]),
        non_targeting_strings=" ".join(config["standard_analyses"]["non_targeting_strings"]),
        outdir=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/standard_analyses_{{source}}_{{processing}}"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/standard_analyses_{{source}}_{{processing}}.log"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        mkdir -p {params.outdir}
        
        # Build command
        CMD="python {input.script} \
            --input-file {input.combined} \
            --outdir {params.outdir} \
            --final-output-file {output.preprocessed} \
            --target-clusters {params.target_clusters} \
            --cutoff {params.guide_cutoff}"
        
        # Add optional parameters if they exist
        if [ -n "{params.target_genes}" ]; then
            CMD="$CMD --target-genes {params.target_genes}"
        fi
        
        if [ -n "{params.stratification_column}" ]; then
            CMD="$CMD --stratification-column {params.stratification_column}"
        fi
        
        if [ -n "{params.stratification_values}" ]; then
            CMD="$CMD --stratification-values {params.stratification_values}"
        fi
        
        if [ -n "{params.non_targeting_strings}" ]; then
            CMD="$CMD --non-targeting-strings {params.non_targeting_strings}"
        fi
        
        if [ "{params.use_gpu}" = "True" ]; then
            CMD="$CMD --use-gpu"
        fi
        
        # Execute command
        eval $CMD &> {log}
        """