# =============================================================================
# DOWNSTREAM ANALYSIS PIPELINE
# =============================================================================
# This file contains rules for downstream analysis after initial processing
# including sublibrary combination, standard analyses, and UMAP generation
#
# Prerequisites: Run preprocessing.smk first to generate QC metrics and cell calling
#
# To run: snakemake -s downstream.smk --configfile config.yaml

import os
import sys
from datetime import datetime
from pathlib import Path
from scripts.pipeline_utils import get_guide_gex_pairings
from scripts.snakemake_helpers import (
    # Path helper functions
    get_scratch_path, get_results_path, get_logs_path,
    get_reference_path, get_raw_data_path, print_path_configuration,
    # Sample management functions
    load_sample_info, get_sample_ids, get_samples_by_type,
    extract_pool, extract_sample, get_sample_pool,
    # File finding functions
    find_fastq_file, print_sample_summary,
    # Output generation functions
    get_downstream_outputs
)

# Define base paths using helper functions
SCRATCH = get_scratch_path(config=config)
RESULTS = get_results_path(config=config)
LOGS = get_logs_path(config=config)
REFERENCES = get_reference_path(config=config)

# Load sample information and IDs
IDS = get_sample_ids(config)
GEX_IDS = get_samples_by_type('gex', config)
GUIDE_IDS = get_samples_by_type('guide', config)
# Get guide-GEX pairings from the centralized function
guide_to_gex, gex_to_guide = get_guide_gex_pairings(config['sample_info_file'])

# Wrapper function for load_sample_info  
def load_sample_info_wrapper():
    return load_sample_info(config)

rule all:
    """Target rule for downstream analysis pipeline with complete report generation"""
    input:
        # All preprocessed files based on configuration
        preprocessed_files=[f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{source}_{processing}.h5ad"
                           for source, processing in config['combinations']],
        # UMAP plots for each preprocessed file
        umap_plots=[f"{RESULTS}/downstream_report/plots/umap/{source}_{processing}.complete"
                   for source, processing in config['combinations']],
        # Pseudobulk TMM results
        pseudobulk_files=[f"{RESULTS}/pseudobulk/{source}_{processing}/pseudobulk_tmm_cpm.tsv"
                         for source, processing in config['combinations']],
        # Final complete report with all analyses
        final_report=f"{RESULTS}/downstream_report/COMPLETE_REPORT_DONE.txt"


# =============================================================================
# SUBLIBRARY COMBINATION
# =============================================================================
rule combine_sublibraries:
    """Combine cell-called sublibraries into a single analysis-ready file
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The combine_sublibraries.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        # Annotated h5ad files (have annotations but need cell calling applied)
        h5ad_files=lambda wildcards: [
            f"{SCRATCH}/{row['sample_id']}/kb_all_{wildcards.source}_{wildcards.processing}/counts_filtered/adata.h5ad"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Cell barcode files for the chosen method
        barcode_files=lambda wildcards: [
            f"{RESULTS}/preprocessing_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/cell_calling/{row['sample_id']}_{config['cell_calling']['default_method']}_cell_barcodes.txt"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Per-sample QC cell list files (generated by QC metrics rules)
        filter_files=lambda wildcards: [
            f"{RESULTS}/preprocessing_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/qc_cell_lists.tsv"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Per-sample GMM threshold tables
        threshold_tables=lambda wildcards: [
            f"{RESULTS}/preprocessing_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/qc_metrics/gmm_thresholds_per_cell.tsv"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        script="scripts/combine_sublibraries.py"
    output:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad"
    params:
        cell_calling_method=config['cell_calling']['default_method'],
        config_file=workflow.configfiles[0]
    log:
        f"{LOGS}/combine_sublibraries_{{source}}_{{processing}}.log"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        python {input.script} \
            --h5ad-files {input.h5ad_files} \
            --barcode-files {input.barcode_files} \
            --filter-files {input.filter_files} \
            --threshold-tables {input.threshold_tables} \
            --cell-calling-method {params.cell_calling_method} \
            --config {params.config_file} \
            --output {output.combined} \
            &> {log}
        """


# =============================================================================
# PERTURBATION PREPROCESSING AND ANALYSIS  
# =============================================================================
rule standard_analyses:
    """Standard analyses including normalization, HVG selection, clustering, UMAP, 
    cell cycle scoring, differential expression, and gene scoring.
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The standard_analyses.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad",
        script="scripts/standard_analyses.py"
    output:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad"
    params:
        outdir=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/standard_analyses_{{source}}_{{processing}}",
        config_file=workflow.configfiles[0]
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/standard_analyses_{{source}}_{{processing}}.log"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        mkdir -p {params.outdir}
        
        python {input.script} \
            --config-file {params.config_file} \
            --input-file {input.combined} \
            --outdir {params.outdir} \
            --final-output-file {output.preprocessed} \
            &> {log}
        """


rule plot_standard_analyses_umap:
    """Generate UMAP plots from preprocessed standard_analyses output.
    
    Creates individual PNG files for dashboard integration with visualizations colored by:
    - QC metrics (mt%, ribo%, total counts, etc.)
    - Cell cycle scores
    - Target gene categories and DE scores
    - Guide MOI categories
    - Leiden clustering results
    """
    input:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad",
        script="scripts/plot_standard_analyses_umap.py"
    output:
        plot_dir=directory(f"{RESULTS}/downstream_report/plots/umap/{{source}}_{{processing}}"),
        complete=f"{RESULTS}/downstream_report/plots/umap/{{source}}_{{processing}}.complete"
    params:
        outdir=f"{RESULTS}/downstream_report/plots/umap/{{source}}_{{processing}}"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/plot_standard_analyses_umap_{{source}}_{{processing}}.log"
    threads: 1
    resources:
        mem_mb=16000  # 16GB for plotting
    shell:
        """
        python {input.script} \
            --input-file {input.preprocessed} \
            --output-dir {params.outdir} &> {log}
        """


# =============================================================================
# PSEUDOBULK ANALYSIS WITH TMM NORMALIZATION
# =============================================================================
rule pseudobulk_tmm:
    """Generate pseudobulk expression profiles with TMM normalization
    
    WARNING: This rule is UNTESTED and may need adjustments for your data.
    
    Aggregates single-cell expression by specified grouping variables
    (e.g., biological_sample, perturbation) and applies TMM normalization
    using edgeR for compositional bias correction.
    
    Outputs:
    - Raw pseudobulk counts
    - TMM-normalized CPM
    - Simple CPM (without normalization factors)
    - Group and gene metadata
    """
    input:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad",
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad",
        script="scripts/pseudobulk_tmm_normalization.py",
        r_script="scripts/run_edger_tmm.R"
    output:
        tmm_cpm=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}/pseudobulk_tmm_cpm.tsv",
        simple_cpm=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}/pseudobulk_simple_cpm.tsv",
        raw_counts=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}/pseudobulk_raw_counts.tsv",
        group_metadata=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}/pseudobulk_group_metadata.tsv",
        gene_metadata=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}/pseudobulk_gene_metadata.tsv"
    params:
        output_dir=f"{RESULTS}/pseudobulk/{{source}}_{{processing}}",
        groupby_cols=lambda wildcards: ' '.join(config.get('pseudobulk', {}).get('groupby_cols', ['biological_sample'])),
        covariate_cols=lambda wildcards: ' '.join(config.get('pseudobulk', {}).get('covariate_cols', ['pct_counts_mt', 'total_counts'])),
        output_prefix="pseudobulk"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/pseudobulk_tmm_{{source}}_{{processing}}.log"
    threads: 2
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        mkdir -p {params.output_dir}
        
        # Load R module for edgeR
        ml R/4.4 2>/dev/null || echo "R module not loaded - using system R"
        
        # Run pseudobulk analysis
        python {input.script} \
            --input-file {input.preprocessed} \
            --raw-file {input.combined} \
            --output-dir {params.output_dir} \
            --groupby-cols {params.groupby_cols} \
            --covariate-cols {params.covariate_cols} \
            --output-prefix {params.output_prefix} \
            &> {log}
        
        # Unload R module
        ml purge 2>/dev/null || true
        
        echo "Pseudobulk analysis complete. Results in {params.output_dir}" | tee -a {log}
        """


# =============================================================================
# FINAL REPORT GENERATION
# =============================================================================
rule generate_downstream_report:
    """Package UMAP plots from downstream analyses for laptop viewing with Streamlit dashboard
    
    This generates a dashboard specifically for downstream analysis outputs:
    - UMAP visualizations from standard analyses
    - Clustering results
    - Differential expression scores
    
    Note: QC metrics are packaged separately by preprocessing.smk
    Run this after all downstream analyses are complete.
    """
    input:
        # Get all downstream outputs (primarily UMAP plots)
        files=get_downstream_outputs(config, report_dir="downstream_report"),
        sample_info=config['sample_info_file'],
        dashboard_script="scripts/streamlit_qc_dashboard_optimized.py",
        package_script="scripts/package_qc_for_laptop_fast_no_json.py"
    output:
        done=f"{RESULTS}/downstream_report/COMPLETE_REPORT_DONE.txt"
    params:
        timestamp=lambda wildcards: datetime.now().strftime("%Y%m%d_%H%M%S")
    log:
        f"{LOGS}/generate_downstream_report.log"
    shell:
        """
        echo "Generating downstream analysis dashboard (UMAP plots)..." | tee {log}
        
        # Run packaging script with 'complete' suffix to distinguish from basic report
        python -u {input.package_script} \
            --qc-report-dir {RESULTS}/downstream_report \
            --sample-info {input.sample_info} \
            --dashboard-script {input.dashboard_script} \
            --output-archive {RESULTS}/qc_dashboard_downstream_{params.timestamp}.tar.gz \
            --per-cell-method-filter {config[cell_calling][default_method]} \
            --guide-cutoff-filter 1,2 \
            --threads {threads} &>> {log}
        
        # Create done file
        touch {output.done}
        
        echo "Downstream dashboard generated: qc_dashboard_downstream_{params.timestamp}.tar.gz" | tee -a {log}
        """
