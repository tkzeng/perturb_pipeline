# =============================================================================
# DOWNSTREAM ANALYSIS PIPELINE
# =============================================================================
# This file contains rules for downstream analysis after initial processing
# including sublibrary combination, standard analyses, and UMAP generation
#
# Prerequisites: Run preprocessing.smk first to generate QC metrics and cell calling
#
# To run: snakemake -s downstream.smk --configfile config.yaml

import os
import sys
from datetime import datetime
from pathlib import Path
from scripts.pipeline_utils import get_guide_gex_pairings
from scripts.snakemake_helpers import (
    # Path helper functions
    get_scratch_path, get_results_path, get_logs_path,
    get_reference_path, get_raw_data_path, print_path_configuration,
    # Sample management functions
    load_sample_info, get_sample_ids, get_samples_by_type,
    extract_pool, extract_sample, get_sample_pool,
    # File finding functions
    find_fastq_file, print_sample_summary,
    # Output generation functions
    get_all_outputs
)

# Define base paths using helper functions
SCRATCH = get_scratch_path(config=config)
RESULTS = get_results_path(config=config)
LOGS = get_logs_path(config=config)
REFERENCES = get_reference_path(config=config)

# Load sample information and IDs
IDS = get_sample_ids(config)
GEX_IDS = get_samples_by_type('gex', config)
GUIDE_IDS = get_samples_by_type('guide', config)
# Get guide-GEX pairings from the centralized function
guide_to_gex, gex_to_guide = get_guide_gex_pairings(config['sample_info_file'])

# Wrapper function for load_sample_info  
def load_sample_info_wrapper():
    return load_sample_info(config)

rule all:
    """Target rule for downstream analysis pipeline with complete report generation"""
    input:
        # All preprocessed files based on configuration
        preprocessed_files=[f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{source}_{processing}.h5ad"
                           for source, processing in config['combinations']],
        # UMAP plots for each preprocessed file
        umap_plots=[f"{RESULTS}/qc_report/plots/umap/{source}_{processing}.complete"
                   for source, processing in config['combinations']],
        # Final complete report with all analyses
        final_report=f"{RESULTS}/qc_report/COMPLETE_REPORT_DONE.txt"


# =============================================================================
# SUBLIBRARY COMBINATION
# =============================================================================
rule combine_sublibraries:
    """Combine cell-called sublibraries into a single analysis-ready file
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The combine_sublibraries.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        # Annotated h5ad files (have annotations but need cell calling applied)
        h5ad_files=lambda wildcards: [
            f"{SCRATCH}/{row['sample_id']}/kb_all_{wildcards.source}_{wildcards.processing}/counts_filtered/adata.h5ad"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Cell barcode files for the chosen method
        barcode_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/cell_calling/{row['sample_id']}_{config['combined_sublibraries']['cell_calling_method']}_cell_barcodes.txt"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Per-sample QC cell list files (generated by QC metrics rules)
        filter_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/qc_cell_lists.tsv"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        script="scripts/combine_sublibraries.py"
    output:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad"
    params:
        cell_calling_method=config['combined_sublibraries']['cell_calling_method']
    log:
        f"{LOGS}/combine_sublibraries_{{source}}_{{processing}}.log"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        python {input.script} \
            --h5ad-files {input.h5ad_files} \
            --barcode-files {input.barcode_files} \
            --filter-files {input.filter_files} \
            --cell-calling-method {params.cell_calling_method} \
            --output {output.combined} \
            &> {log}
        """


# =============================================================================
# PERTURBATION PREPROCESSING AND ANALYSIS  
# =============================================================================
rule standard_analyses:
    """Standard analyses including normalization, HVG selection, clustering, UMAP, 
    cell cycle scoring, differential expression, and gene scoring.
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The standard_analyses.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad",
        script="scripts/standard_analyses.py"
    output:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad"
    params:
        outdir=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/standard_analyses_{{source}}_{{processing}}",
        config_file=workflow.configfiles[0]
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/standard_analyses_{{source}}_{{processing}}.log"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        mkdir -p {params.outdir}
        
        python {input.script} \
            --config-file {params.config_file} \
            --input-file {input.combined} \
            --outdir {params.outdir} \
            --final-output-file {output.preprocessed} \
            &> {log}
        """


rule plot_standard_analyses_umap:
    """Generate UMAP plots from preprocessed standard_analyses output.
    
    Creates individual PNG files for dashboard integration with visualizations colored by:
    - QC metrics (mt%, ribo%, total counts, etc.)
    - Cell cycle scores
    - Target gene categories and DE scores
    - Guide MOI categories
    - Leiden clustering results
    """
    input:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad",
        script="scripts/plot_standard_analyses_umap.py"
    output:
        plot_dir=directory(f"{RESULTS}/qc_report/plots/umap/{{source}}_{{processing}}"),
        complete=f"{RESULTS}/qc_report/plots/umap/{{source}}_{{processing}}.complete"
    params:
        outdir=f"{RESULTS}/qc_report/plots/umap/{{source}}_{{processing}}"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/plot_standard_analyses_umap_{{source}}_{{processing}}.log"
    threads: 1
    resources:
        mem_mb=16000  # 16GB for plotting
    shell:
        """
        python {input.script} \
            --input-file {input.preprocessed} \
            --output-dir {params.outdir} &> {log}
        """


# =============================================================================
# FINAL REPORT GENERATION
# =============================================================================
rule generate_final_report:
    """Package UMAP plots from downstream analyses for laptop viewing with Streamlit dashboard
    
    This generates a dashboard specifically for downstream analysis outputs:
    - UMAP visualizations from standard analyses
    - Clustering results
    - Differential expression scores
    
    Note: QC metrics are packaged separately by preprocessing.smk
    Run this after all downstream analyses are complete.
    """
    input:
        # Get all UMAP plots including subsets from get_all_outputs
        files=lambda wildcards: [f for category in get_all_outputs(config, as_dict=True).keys() 
                                 if category.startswith('umap')
                                 for f in get_all_outputs(config, as_dict=True)[category]],
        sample_info=config['sample_info_file'],
        dashboard_script="scripts/streamlit_qc_dashboard_optimized.py",
        package_script="scripts/package_qc_for_laptop_fast_no_json.py"
    output:
        done=f"{RESULTS}/qc_report/COMPLETE_REPORT_DONE.txt"
    params:
        timestamp=lambda wildcards: datetime.now().strftime("%Y%m%d_%H%M%S")
    log:
        f"{LOGS}/generate_final_report.log"
    shell:
        """
        echo "Generating downstream analysis dashboard (UMAP plots)..." | tee {log}
        
        # Create temporary file with input list
        TMPFILE=$(mktemp /tmp/qc_files_complete_XXXXXX.txt)
        for f in {input.files}; do
            echo "$f" >> $TMPFILE
        done
        
        # Run packaging script with 'complete' suffix to distinguish from basic report
        python -u {input.package_script} \
            --input-file-list $TMPFILE \
            --sample-info {input.sample_info} \
            --dashboard-script {input.dashboard_script} \
            --output-archive {RESULTS}/qc_dashboard_downstream_{params.timestamp}.tar.gz \
            --per-cell-method-filter {config[cell_calling][default_method]} \
            --guide-cutoff-filter 1,2 \
            --threads {threads} &>> {log}
        
        # Clean up temp file
        rm -f $TMPFILE
        
        # Create done file
        touch {output.done}
        
        echo "Downstream dashboard generated: qc_dashboard_downstream_{params.timestamp}.tar.gz" | tee -a {log}
        """