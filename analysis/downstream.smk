# =============================================================================
# DOWNSTREAM ANALYSIS PIPELINE
# =============================================================================
# This file contains rules for downstream analysis after initial processing
# including sublibrary combination and perturbation preprocessing
#
# To run: snakemake -s downstream.smk all_preprocessed --configfile config.yaml

import os
import sys
from scripts.pipeline_utils import get_guide_gex_pairings
from scripts.snakemake_helpers import (
    # Path helper functions
    get_scratch_path, get_results_path, get_logs_path,
    get_reference_path, get_raw_data_path, print_path_configuration,
    # Sample management functions
    load_sample_info, get_sample_ids, get_samples_by_type,
    extract_pool, extract_sample, get_sample_pool,
    # File finding functions
    find_fastq_file, print_sample_summary,
    # Output generation functions
    get_all_outputs
)

# Define base paths using helper functions
SCRATCH = get_scratch_path(config=config)
RESULTS = get_results_path(config=config)
LOGS = get_logs_path(config=config)
REFERENCES = get_reference_path(config=config)

# Load sample information and IDs
IDS = get_sample_ids(config)
GEX_IDS = get_samples_by_type('gex', config)
GUIDE_IDS = get_samples_by_type('guide', config)
# Get guide-GEX pairings from the centralized function
guide_to_gex, gex_to_guide = get_guide_gex_pairings(config['sample_info_file'])

# Wrapper function for load_sample_info  
def load_sample_info_wrapper():
    return load_sample_info(config)

rule all_preprocessed:
    """Target rule for downstream preprocessing pipeline"""
    input:
        # All preprocessed files based on configuration
        expand(f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad",
               source=["main", "all"],
               processing=["raw", "merged"])


# =============================================================================
# SUBLIBRARY COMBINATION
# =============================================================================
rule combine_sublibraries:
    """Combine cell-called sublibraries into a single analysis-ready file
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The combine_sublibraries.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        # Annotated h5ad files (have annotations but need cell calling applied)
        h5ad_files=lambda wildcards: [
            f"{SCRATCH}/{row['sample_id']}/kb_all_{wildcards.source}_{wildcards.processing}/counts_filtered/adata.h5ad"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Cell barcode files for the chosen method
        barcode_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/cell_calling/{row['sample_id']}_{config['combined_sublibraries']['cell_calling_method']}_cell_barcodes.txt"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        # Per-sample QC cell list files (generated by QC metrics rules)
        filter_files=lambda wildcards: [
            f"{RESULTS}/qc_report/data/per_sample/{wildcards.source}_{wildcards.processing}/{row['sample_id']}/qc_cell_lists.tsv"
            for _, row in load_sample_info(config).iterrows()
            if row['sample_type'] == 'gex'
        ],
        script="scripts/combine_sublibraries.py"
    output:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad"
    params:
        cell_calling_method=config['combined_sublibraries']['cell_calling_method'],
        pools=" ".join(config['combined_sublibraries']['pools']) if config['combined_sublibraries']['pools'] else "",
        qc_method=config['combined_sublibraries'].get('qc_method', 'gmm_2d_posterior_75')
    log:
        f"{LOGS}/combine_sublibraries_{{source}}_{{processing}}.log"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        python {input.script} \
            --h5ad-files {input.h5ad_files} \
            --barcode-files {input.barcode_files} \
            --filter-files {input.filter_files} \
            --cell-calling-method {params.cell_calling_method} \
            --output {output.combined} \
            --pools {params.pools} \
            --qc-method {params.qc_method} \
            &> {log}
        """


# =============================================================================
# PERTURBATION PREPROCESSING AND ANALYSIS  
# =============================================================================
rule standard_analyses:
    """Standard analyses including normalization, HVG selection, clustering, UMAP, 
    cell cycle scoring, differential expression, and gene scoring.
    
    WARNING: THIS RULE IS IN DEVELOPMENT AND NOT READY FOR USE
    The standard_analyses.py script and related functionality 
    are still being tested and may not work correctly. Do not use this rule
    for production analysis yet.
    """
    input:
        combined=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/combined_{{source}}_{{processing}}.h5ad",
        script="scripts/standard_analyses.py"
    output:
        preprocessed=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessed_{{source}}_{{processing}}.h5ad"
    params:
        target_genes=config.get("preprocessing", {}).get("target_genes", ["TP53", "CDKN1A"]),
        use_gpu=config.get("preprocessing", {}).get("use_gpu", False),
        target_clusters=config.get("preprocessing", {}).get("target_clusters", 3),
        stratification_column=config.get("preprocessing", {}).get("stratification", {}).get("column", "condition"),
        stratification_values=config.get("preprocessing", {}).get("stratification", {}).get("values", ["72hr_wt", "168hr_wt"]),
        non_targeting_strings=config.get("preprocessing", {}).get("non_targeting_strings", ["non-targeting", "non.targeting"]),
        outdir=f"{RESULTS}/{config['combined_sublibraries']['output_dir']}/preprocessing_{{source}}_{{processing}}"
    wildcard_constraints:
        source="main|undetermined|all",
        processing="raw|recovered|merged"
    log:
        f"{LOGS}/standard_analyses_{{source}}_{{processing}}.log"
    threads: 4
    resources:
        mem_mb=config["resources"]["analysis"]["mem_mb"]
    shell:
        """
        mkdir -p {params.outdir}
        
        python {input.script} \
            --input-file {input.combined} \
            --outdir {params.outdir} \
            --final-output-file {output.preprocessed} \
            --target-genes {params.target_genes} \
            --target-clusters {params.target_clusters} \
            --stratification-column {params.stratification_column} \
            --stratification-values {params.stratification_values} \
            --non-targeting-strings {params.non_targeting_strings} \
            --cutoff 5 \
            $([[ "{params.use_gpu}" == "True" ]] && echo "--use-gpu" || echo "") \
            &> {log}
        """